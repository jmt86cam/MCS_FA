{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef89ac-2913-4058-9754-81b2c4f2260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an environment with devbio-napari installed in it.\n",
    "mamba create --name neurite-devbio-napari-env python=3.9 devbio-napari -c conda-forge\n",
    "\n",
    "# Activate the environment\n",
    "conda activate neurite-devbio-napari-env\n",
    "\n",
    "# Open Jupyter\n",
    "jupyter lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc97aae4-285c-4298-ad3e-73fc860cf1f4",
   "metadata": {},
   "source": [
    "### Set folder directory and inspect image shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2773f398-0014-42d0-9c46-598f8009565e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage.io import imread\n",
    "\n",
    "folder_dir =  os.path.join(os.path.dirname(__file__), \"../images\")\n",
    "\n",
    "# List all TIFF images\n",
    "files = [f for f in os.listdir(folder_dir) if f.endswith(\".tif\")]\n",
    "print(f\"Found {len(files)} images.\")\n",
    "\n",
    "# Pick one image (index 0 for example)\n",
    "img_path = os.path.join(folder_dir, files[0])\n",
    "img = imread(img_path)\n",
    "print(f\"Loaded {files[0]} with shape: {img.shape}\")\n",
    "\n",
    "print(\"\\nCheck the shape above.\")\n",
    "print(\"If your image shape is (H, W, C), channel_axis = -1\")\n",
    "print(\"If your image shape is (C, H, W), channel_axis = 0\")\n",
    "channel_axis = int(input(\"Enter the channel axis index: \"))\n",
    "print(f\"Using channel_axis = {channel_axis} for this dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be769b9c-3d18-44f9-b990-54a388686177",
   "metadata": {},
   "source": [
    "### Save cell and background masks, pixel sizes, background values ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a202914-a70f-48cf-a6fd-25d469ff3306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import pandas as pd\n",
    "import napari\n",
    "from qtpy.QtWidgets import QPushButton\n",
    "\n",
    "CHANNEL1 = \"channel1\"  \n",
    "CHANNEL2 = \"channel2\"\n",
    "\n",
    "# 1. Load images\n",
    "def load_images(folder_dir):\n",
    "    files = [f for f in os.listdir(folder_dir) if f.endswith(\".tif\")]\n",
    "    ImsFP = [os.path.join(folder_dir, f) for f in files]\n",
    "    ImNames = files\n",
    "    Ims = [tifffile.imread(path) for path in ImsFP]\n",
    "    print(f\"Loaded {len(Ims)} images from {folder_dir}\")\n",
    "    return Ims, ImsFP, ImNames\n",
    "\n",
    "# 2. Extract pixel sizes\n",
    "def extract_pixel_sizes(ImsFP):\n",
    "    pixel_data = []\n",
    "    for path in ImsFP:\n",
    "        with tifffile.TiffFile(path) as tif:\n",
    "            tags = tif.pages[0].tags\n",
    "            x_res = tags[\"XResolution\"].value[0] / tags[\"XResolution\"].value[1] if \"XResolution\" in tags else None\n",
    "            y_res = tags[\"YResolution\"].value[0] / tags[\"YResolution\"].value[1] if \"YResolution\" in tags else None\n",
    "            x_size = 1/x_res if x_res else None\n",
    "            y_size = 1/y_res if y_res else None\n",
    "            pixel_area = x_size*y_size if x_size and y_size else None\n",
    "            pixel_data.append({\"file\": os.path.splitext(os.path.basename(path))[0], \"x_size\": x_size, \"y_size\": y_size, \"pixel_area\": pixel_area})\n",
    "    return pd.DataFrame(pixel_data)\n",
    "\n",
    "# 3. Check for existing masks\n",
    "def check_existing_masks(folder_dir, file_name):\n",
    "    mask_dir = os.path.join(folder_dir, \"CellMasks\")\n",
    "    if not os.path.exists(mask_dir):\n",
    "        return None, None\n",
    "\n",
    "    base = os.path.splitext(file_name)[0]\n",
    "\n",
    "    # Cell masks\n",
    "    cell_masks = sorted([\n",
    "        os.path.join(mask_dir, f) \n",
    "        for f in os.listdir(mask_dir) \n",
    "        if f.startswith(base + \"_cell\") and f.endswith(\".tif\")\n",
    "    ])\n",
    "    # Background mask\n",
    "    bg_mask_path = os.path.join(mask_dir, f\"{base}_background.tif\")\n",
    "    if not os.path.exists(bg_mask_path):\n",
    "        bg_mask_path = None\n",
    "\n",
    "    return cell_masks, bg_mask_path\n",
    "\n",
    "# 4. Measure background from existing mask\n",
    "def measure_background_from_mask(img, bg_mask_path, file_name, bg_csv):\n",
    "    mask = tifffile.imread(bg_mask_path).astype(bool)\n",
    "    MIP = img.max(axis=0)\n",
    "\n",
    "    # MIP metrics\n",
    "    c1_vals_MIP = MIP[1][mask]\n",
    "    c2_vals_MIP = MIP[0][mask]\n",
    "    bg_c1_MIP     = np.mean(c1_vals_MIP)\n",
    "    bg_c1_MIP_med = np.median(c1_vals_MIP)\n",
    "    bg_c2_MIP     = np.mean(c2_vals_MIP)\n",
    "    bg_c2_MIP_med = np.median(c2_vals_MIP)\n",
    "\n",
    "    # Full Z-stack metrics\n",
    "    c1_vals_Z = img[:,1][..., mask].flatten()\n",
    "    c2_vals_Z = img[:,0][..., mask].flatten()\n",
    "    bg_c1_Z     = np.mean(c1_vals_Z)\n",
    "    bg_c1_Z_med = np.median(c1_vals_Z)\n",
    "    bg_c2_Z     = np.mean(c2_vals_Z)\n",
    "    bg_c2_Z_med = np.median(c2_vals_Z)\n",
    "\n",
    "    df = pd.DataFrame([[file_name, bg_c1_MIP, bg_c1_MIP_med, bg_c1_Z, bg_c1_Z_med,\n",
    "                        bg_c2_MIP, bg_c2_MIP_med, bg_c2_Z, bg_c2_Z_med]],\n",
    "                      columns=[\"file\",\n",
    "                               f\"Bg_{CHANNEL1}_MIP\", f\"Bg_{CHANNEL1}_MIP_median\",\n",
    "                               f\"Bg_{CHANNEL1}_Zmean\", f\"Bg_{CHANNEL1}_Zmedian\",\n",
    "                               f\"Bg_{CHANNEL2}_MIP\", f\"Bg_{CHANNEL2}_MIP_median\",\n",
    "                               f\"Bg_{CHANNEL2}_Zmean\", f\"Bg_{CHANNEL2}_Zmedian\"])\n",
    "    df.to_csv(bg_csv, mode='a', header=not os.path.exists(bg_csv), index=False)\n",
    "    print(f\"Saved background values for {file_name}\")\n",
    "\n",
    "# 5. Draw masks + background\n",
    "def draw_masks_and_background(img, MIP, file_name, mask_dir, bg_csv, channel_axis=0):\n",
    "    os.makedirs(mask_dir, exist_ok=True)\n",
    "    viewer = napari.view_image(MIP, name=file_name, channel_axis=channel_axis)\n",
    "\n",
    "    # Cell masks\n",
    "    mask_layer = viewer.add_shapes(name=\"Cell masks\")\n",
    "    def save_masks_on_close():\n",
    "        masks_stack = mask_layer.to_masks(MIP.shape[1:])\n",
    "        if masks_stack.shape[0] == 0:\n",
    "            print(\"No cell masks drawn, skipping save.\")\n",
    "            return\n",
    "        file_basename = os.path.splitext(file_name)[0]\n",
    "        for idx, mask in enumerate(masks_stack, start=1):\n",
    "            mask_to_save = (mask > 0).astype(np.uint8) * 255\n",
    "            tifffile.imwrite(os.path.join(mask_dir, f\"{file_basename}_cell{idx}.tif\"), mask_to_save)\n",
    "        print(f\"Saved {len(masks_stack)} masks to: {mask_dir}\")\n",
    "\n",
    "    button_masks = QPushButton(\"Save cell masks\")\n",
    "    button_masks.clicked.connect(save_masks_on_close)\n",
    "    viewer.window.add_dock_widget(button_masks)\n",
    "\n",
    "    # Background\n",
    "    bg_layer = viewer.add_shapes(name=\"Background\")\n",
    "    def save_background():\n",
    "        mask = bg_layer.to_masks(MIP.shape[1:]).max(axis=0)\n",
    "        if mask.sum() < 1:\n",
    "            print(\"No background region drawn!\")\n",
    "            return\n",
    "        mask_path = os.path.join(mask_dir, f\"{os.path.splitext(file_name)[0]}_background.tif\")\n",
    "        tifffile.imwrite(mask_path, (mask > 0).astype(np.uint8)*255)\n",
    "        print(f\"Saved background region for {file_name}\")\n",
    "\n",
    "        # MIP metrics\n",
    "        mask_bool = mask.astype(bool)\n",
    "        c1_vals_MIP = MIP[1][mask_bool]\n",
    "        c2_vals_MIP = MIP[0][mask_bool]\n",
    "        bg_c1_MIP     = np.mean(c1_vals_MIP)\n",
    "        bg_c1_MIP_med = np.median(c1_vals_MIP)\n",
    "        bg_c2_MIP     = np.mean(c2_vals_MIP)\n",
    "        bg_c2_MIP_med = np.median(c2_vals_MIP)\n",
    "\n",
    "        # Full Z-stack metrics\n",
    "        c1_vals_Z = img[:,1][..., mask_bool].flatten()\n",
    "        c2_vals_Z = img[:,0][..., mask_bool].flatten()\n",
    "        bg_c1_Z     = np.mean(c1_vals_Z)\n",
    "        bg_c1_Z_med = np.median(c1_vals_Z)\n",
    "        bg_c2_Z     = np.mean(c2_vals_Z)\n",
    "        bg_c2_Z_med = np.median(c2_vals_Z)\n",
    "\n",
    "        # Save to CSV\n",
    "        df = pd.DataFrame([[file_name, bg_c1_MIP, bg_c1_MIP_med, bg_c1_Z, bg_c1_Z_med,\n",
    "                            bg_c2_MIP, bg_c2_MIP_med, bg_c2_Z, bg_c2_Z_med]],\n",
    "                          columns=[\"file\",\n",
    "                                   f\"Bg_{CHANNEL1}_MIP\", f\"Bg_{CHANNEL1}_MIP_median\",\n",
    "                                   f\"Bg_{CHANNEL1}_Zmean\", f\"Bg_{CHANNEL1}_Zmedian\",\n",
    "                                   f\"Bg_{CHANNEL2}_MIP\", f\"Bg_{CHANNEL2}_MIP_median\",\n",
    "                                   f\"Bg_{CHANNEL2}_Zmean\", f\"Bg_{CHANNEL2}_Zmedian\"])\n",
    "        df.to_csv(bg_csv, mode='a', header=not os.path.exists(bg_csv), index=False)\n",
    "        print(f\"Saved background values for {file_name}\")\n",
    "\n",
    "    button_bg = QPushButton(\"Save background region\")\n",
    "    button_bg.clicked.connect(save_background)\n",
    "    viewer.window.add_dock_widget(button_bg)\n",
    "\n",
    "    viewer.show(block=True)\n",
    "\n",
    "# 6. Run pipeline\n",
    "def run_pipeline(folder_dir, channel_axis=0):\n",
    "    Ims, ImsFP, ImNames = load_images(folder_dir)\n",
    "    \n",
    "    pixel_csv = os.path.join(folder_dir, \"pixel_sizes.csv\")\n",
    "    bg_csv    = os.path.join(folder_dir, \"background_values.csv\")\n",
    "    \n",
    "    # Remove existing CSVs so we start fresh\n",
    "    if os.path.exists(pixel_csv):\n",
    "        os.remove(pixel_csv)\n",
    "    if os.path.exists(bg_csv):\n",
    "        os.remove(bg_csv)\n",
    "\n",
    "    # Save pixel sizes\n",
    "    pixel_df = extract_pixel_sizes(ImsFP)\n",
    "    pixel_df.to_csv(pixel_csv, index=False)\n",
    "\n",
    "    for img, name in zip(Ims, ImNames):\n",
    "        base = os.path.splitext(name)[0]\n",
    "        mask_dir = os.path.join(folder_dir, \"CellMasks\")\n",
    "        print(f\"\\n=== Processing {base} ===\")\n",
    "\n",
    "        # Check existing masks\n",
    "        cell_masks, bg_mask_path = check_existing_masks(folder_dir, base)\n",
    "\n",
    "        if bg_mask_path is not None:\n",
    "            measure_background_from_mask(img, bg_mask_path, base, bg_csv)\n",
    "            print(f\"Measured background from existing mask for {base}\")\n",
    "        else:\n",
    "            MIP = img.max(axis=0)\n",
    "            draw_masks_and_background(img, MIP, base, mask_dir, bg_csv, channel_axis=channel_axis)\n",
    "        print(f\"Finished processing {base}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline(folder_dir, channel_axis=0)\n",
    "\n",
    "print(f\"\\nFinished processing for {folder_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e2e8a8-b028-428f-9bed-0afd8f32fb73",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Open each cell, save a masked cell within the bounding box, also save the cell area ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cab381-1c46-43b0-9d8b-60da8a5b8019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Extract cropped 4D cell stack + mask area + bbox area\n",
    "def extract_cell_stack(img_4d, mask_path):\n",
    "    mask = tifffile.imread(mask_path) > 0\n",
    "\n",
    "    rows, cols = np.nonzero(mask)\n",
    "    if len(rows) == 0:\n",
    "        return None, None, None, None\n",
    "\n",
    "    min_r, max_r = np.min(rows), np.max(rows)\n",
    "    min_c, max_c = np.min(cols), np.max(cols)\n",
    "\n",
    "    cropped = img_4d[:, :, min_r:max_r+1, min_c:max_c+1]\n",
    "\n",
    "    mask_area = np.sum(mask)\n",
    "    bbox_area = (max_r - min_r + 1) * (max_c - min_c + 1)\n",
    "\n",
    "    return cropped, mask_area, bbox_area, (min_r, max_r, min_c, max_c)\n",
    "\n",
    "# 2. Save cropped cell stack to TIFF\n",
    "def save_cropped_cell(cropped_stack, output_dir, base, cell_index):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    save_path = os.path.join(output_dir, f\"{base}_cell{cell_index}.tif\")\n",
    "    tifffile.imwrite(save_path, cropped_stack.astype(cropped_stack.dtype), imagej=True, metadata={'axes': 'ZCYX'})\n",
    "\n",
    "    return save_path\n",
    "\n",
    "# 3. Run pipeline\n",
    "def process_cells(folder_dir):\n",
    "    mask_dir = os.path.join(folder_dir, \"CellMasks\")\n",
    "    output_dir = os.path.join(folder_dir, \"Cells\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    csv_path = os.path.join(folder_dir, \"cell_measurements.csv\")\n",
    "    cells_list = []\n",
    "    cell_names = []\n",
    "    entries = []\n",
    "\n",
    "    # Loop over original images\n",
    "    for fname in os.listdir(folder_dir):\n",
    "        if not fname.endswith(\".tif\"):\n",
    "            continue\n",
    "\n",
    "        base = os.path.splitext(fname)[0]\n",
    "        print(f\"\\n=== Processing {base} ===\")\n",
    "\n",
    "        img_path = os.path.join(folder_dir, fname)\n",
    "        img_4d = tifffile.imread(img_path)\n",
    "\n",
    "        # Collect masks for this image\n",
    "        file_basename = os.path.splitext(os.path.basename(base))[0]\n",
    "        mask_files = sorted(\n",
    "            [f for f in os.listdir(mask_dir) if f.startswith(file_basename + \"_cell\")]\n",
    "        )\n",
    "\n",
    "        if len(mask_files) == 0:\n",
    "            print(\"No masks found for this image.\")\n",
    "            continue\n",
    "\n",
    "        for idx, mask_file in enumerate(mask_files, start=1):\n",
    "            mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "            # --- 1. Extract cropped stack ---\n",
    "            cropped, mask_area, bbox_area, bbox_coords = extract_cell_stack(img_4d, mask_path)\n",
    "\n",
    "            if cropped is None:\n",
    "                print(f\"Empty mask for {mask_file}\")\n",
    "                continue\n",
    "\n",
    "            # --- 2. Save cropped TIFF ---\n",
    "            cell_tif_path = save_cropped_cell(cropped, output_dir, file_basename, idx)\n",
    "\n",
    "\n",
    "            # --- Collect results ---\n",
    "            entries.append([\n",
    "                base,\n",
    "                f\"{file_basename}_cell{idx}.tif\",\n",
    "                mask_area,\n",
    "                bbox_area,\n",
    "                cell_tif_path,\n",
    "                mask_path\n",
    "            ])\n",
    "\n",
    "    # Save results to CSV\n",
    "    df = pd.DataFrame(\n",
    "        entries,\n",
    "        columns=[\"file\", \"cell_image\", \"mask_area\", \"bbox_area\", \"cell_tif_path\", \"mask_path\"]\n",
    "    )\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"\\nSaved measurements to: {csv_path}\")\n",
    "\n",
    "def run_cell_pipeline(folder_dir):\n",
    "    \"\"\"\n",
    "    Run AFTER mask drawing pipeline.\n",
    "    Extract each cell, save TIFF, compute areas\n",
    "    \"\"\"\n",
    "    process_cells(folder_dir)\n",
    "\n",
    "run_cell_pipeline(folder_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc93c56-1cdd-4190-920c-b7e29628a0c7",
   "metadata": {},
   "source": [
    "### Manually open each cell in imageJ and make a csv file with the filename and focal plane ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ac5e04-940a-48d7-9baf-2fde6d5da856",
   "metadata": {},
   "source": [
    "### Combine all csv files into one \"all_cell_details\" csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e1eea11-6fc2-4086-bba9-2ffa6adc0fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pixel_csv = os.path.join(folder_dir, \"pixel_sizes.csv\")\n",
    "bg_csv = os.path.join(folder_dir, \"background_values.csv\")\n",
    "measure_csv = os.path.join(folder_dir, \"cell_measurements.csv\")\n",
    "manual_csv = os.path.join(folder_dir, \"cell_ManualDetails.csv\")\n",
    "\n",
    "# Load the CSV files\n",
    "pixel_df = pd.read_csv(pixel_csv)\n",
    "bg_df = pd.read_csv(bg_csv)\n",
    "measure_df = pd.read_csv(measure_csv)\n",
    "manual_df = pd.read_csv(manual_csv, sep = \";\")\n",
    "manual_df = manual_df.loc[:, ~manual_df.columns.str.contains(\"^Unnamed\")]\n",
    "\n",
    "# Merge on the \"file\" column\n",
    "merged_df1 = pd.merge(pixel_df, bg_df, on=\"file\", how=\"left\")\n",
    "\n",
    "# Merge on the \"cell_image\" column\n",
    "merged_df2 = pd.merge(measure_df, manual_df, on=\"cell_image\", how=\"left\")\n",
    "# Remove duplicated \"file\" column\n",
    "if \"file_x\" in merged_df2.columns and \"file_y\" in merged_df2.columns:\n",
    "    merged_df2[\"file\"] = merged_df2[\"file_x\"]\n",
    "    merged_df2 = merged_df2.drop(columns=[\"file_x\", \"file_y\"])\n",
    "\n",
    "# Merge everything together\n",
    "merged_df = pd.merge(merged_df2, merged_df1, on=\"file\", how=\"left\")      \n",
    "\n",
    "# Save\n",
    "output_path = os.path.join(folder_dir, \"all_cell_details.csv\")\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "del pixel_df, bg_df, measure_df, manual_df, merged_df1, merged_df2, merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946fc860-b414-4fee-87f5-a5bd11a7e682",
   "metadata": {},
   "source": [
    "### Open each image and extract only the focal adhesion plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "848fc8e8-950b-4da7-a255-db037ef2d326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tifffile\n",
    "\n",
    "# Load CSV\n",
    "df_cell_details = pd.read_csv(os.path.join(folder_dir, \"all_cell_details.csv\"))\n",
    "df_cell_details[\"cell_image\"] = df_cell_details[\"cell_image\"].astype(str).str.strip()\n",
    "\n",
    "# Ensure paths are absolute (i.e. contain the full path and not just a bit of it)\n",
    "df_cell_details[\"cell_tif_path\"] = df_cell_details[\"cell_tif_path\"].apply(lambda x: os.path.join(folder_dir, x))\n",
    "df_cell_details[\"mask_path\"]     = df_cell_details[\"mask_path\"].apply(lambda x: os.path.join(folder_dir, x))\n",
    "\n",
    "# Load images and masks in CSV order\n",
    "Ims      = [tifffile.imread(p) for p in df_cell_details[\"cell_tif_path\"]]\n",
    "\n",
    "Masks_raw = [tifffile.imread(p) for p in df_cell_details[\"mask_path\"]]\n",
    "def crop_to_bbox(mask):\n",
    "    # Find the nonzero pixels\n",
    "    ys, xs = np.where(mask > 0)\n",
    "\n",
    "    if len(xs) == 0:\n",
    "        # If mask is empty, just return as-is\n",
    "        return mask\n",
    "    # Bounding box coords\n",
    "    ymin, ymax = ys.min(), ys.max()\n",
    "    xmin, xmax = xs.min(), xs.max()\n",
    "    # Crop\n",
    "    return mask[ymin:ymax+1, xmin:xmax+1]\n",
    "Masks = [crop_to_bbox(m) for m in Masks_raw]\n",
    "\n",
    "# Extract FA-planes\n",
    "Faplane_list = df_cell_details[\"Faplane\"].fillna(1).astype(int).tolist()\n",
    "Names = df_cell_details[\"cell_image\"]\n",
    "\n",
    "FAplane_Ims = [\n",
    "    img[fplane - 1, ...]    # subtract 1 for ImageJ indexing\n",
    "    for img, fplane in zip(Ims, Faplane_list)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f563028-c55e-4872-bc55-972da2107a0e",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a39c1-8494-4284-989b-62b491403cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import napari\n",
    "import pyclesperanto_prototype as cle\n",
    "import napari_segment_blobs_and_things_with_membranes as nsbatwm  \n",
    "import napari_simpleitk_image_processing as nsitk\n",
    "from skimage import measure, morphology, segmentation\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.filters import frangi\n",
    "\n",
    "\n",
    "for FA_sub, CellMask, Name in zip(FAplane_Ims, Masks, Names):\n",
    "    print(f\"Processing {Name}\")\n",
    "    ### MAPPER segmentation and analysis ###\n",
    "    MAPPER_channel = FA_sub[0, :, :] \n",
    "    Sigma = 1\n",
    "    MAPPERGaus = cle.gaussian_blur(MAPPER_channel, None, Sigma, Sigma, 0.0)\n",
    "    Radius = 100\n",
    "    MAPPERGausSubBG = nsbatwm.subtract_background(MAPPERGaus, Radius)\n",
    "    MAPPERGausSubBG[MAPPERGausSubBG < 0] = 0\n",
    "    # laplace box\n",
    "    MAPPER_lbp = cle.laplace_box(MAPPERGausSubBG)\n",
    "    # Threshold huang\n",
    "    MAPPERThresh = nsitk.threshold_huang(MAPPER_lbp)\n",
    "    MAPPERThreshMask = MAPPERThresh*CellMask\n",
    "    # Remove small objects\n",
    "    MAPPER_mask_bool = MAPPERThreshMask.astype(bool)\n",
    "    MAPPER_mask_clean_bool = morphology.remove_small_objects(MAPPER_mask_bool, min_size=5)\n",
    "    MAPPERThreshMask_clean = MAPPER_mask_clean_bool.astype(MAPPERThreshMask.dtype)\n",
    "    # Watershed puncta\n",
    "    MAPPER_distance = ndi.distance_transform_edt(MAPPER_mask_clean_bool)\n",
    "    MAPPER_distance_smooth = ndi.gaussian_filter(MAPPER_distance, sigma=1)\n",
    "    MAPPER_local_maxi = morphology.local_maxima(MAPPER_distance_smooth, connectivity=1)\n",
    "    MAPPER_local_maxi = MAPPER_local_maxi & MAPPER_mask_clean_bool  # ensure maxima only inside mask\n",
    "    MAPPER_markers = measure.label(MAPPER_local_maxi) \n",
    "    MAPPER_labels_ws = segmentation.watershed(-MAPPER_distance_smooth, MAPPER_markers, mask=MAPPER_mask_clean_bool)\n",
    "    # Measure properties of puncta\n",
    "    MAPPER_props_table = measure.regionprops_table(MAPPER_labels_ws, intensity_image=MAPPER_channel,\n",
    "        properties=['label', 'area', 'centroid', 'eccentricity', 'solidity', 'mean_intensity'])\n",
    "    MAPPER_df = pd.DataFrame(MAPPER_props_table)\n",
    "\n",
    "    # Save a tiff of the labelled puncta and also a csv file of the properties\n",
    "    output_dir = os.path.join(folder_dir, \"MAPPER_labels\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    csv_filename = f\"{Name}_MAPPER_labels.csv\"\n",
    "    csv_path = os.path.join(output_dir, csv_filename)\n",
    "    MAPPER_df.to_csv(csv_path, index=False)\n",
    "    # Note that this tiff is labels, not a binary mask, to be considered if loading into ImageJ and for future use.\n",
    "    tif_filename = f\"{Name}_MAPPER_labels.tif\"\n",
    "    tif_path = os.path.join(output_dir, tif_filename)\n",
    "    tifffile.imwrite(tif_path, MAPPER_labels_ws.astype(np.uint16))\n",
    "    \n",
    "    ### FA segmentation and analysis ###\n",
    "    Vinculin_channel = FA_sub[1, :, :]\n",
    "    ## Generate binary image\n",
    "    # Gaussian blur\n",
    "    Sigma = 1\n",
    "    VincGaus = cle.gaussian_blur(Vinculin_channel, None, Sigma, Sigma, 0.0)\n",
    "    # Background subtraction\n",
    "    Radius = 20\n",
    "    VincGausSubBG = nsbatwm.subtract_background(VincGaus, Radius)\n",
    "    VincGausSubBG[VincGausSubBG < 0] = 0\n",
    "    VincGausSubBG = (VincGausSubBG - VincGausSubBG.min()) / (VincGausSubBG.max() - VincGausSubBG.min())\n",
    "    VincGausSubBG[VincGausSubBG < 0.1] = 0\n",
    "    # Threshold and apply cell mask\n",
    "    VincThresh = nsitk.threshold_otsu(VincGausSubBG)\n",
    "    VincThreshMask = VincThresh * CellMask\n",
    "    ## Remove small objects\n",
    "    Vinculin_mask_clean = morphology.remove_small_objects(VincThreshMask.astype(bool), min_size=5)\n",
    "    ## Watershed FAs\n",
    "    Vinculin_distance = ndi.distance_transform_edt(Vinculin_mask_clean)\n",
    "    Vinculin_distance_smooth = ndi.gaussian_filter(Vinculin_distance, sigma=1)\n",
    "    # Generate ridges\n",
    "    Vinculin_ridge = frangi(VincGausSubBG, sigmas=range(1, 7))\n",
    "    Vinculin_ridge_thresh = 0.2 * Vinculin_ridge.max()   # tune 0.15–0.3\n",
    "    Vinculin_ridge_seeds = Vinculin_ridge > Vinculin_ridge_thresh\n",
    "    Vinculin_ridge_markers = measure.label(Vinculin_ridge_seeds)\n",
    "    # Generate seeds\n",
    "    h = 0.8\n",
    "    Vinculin_h_min = morphology.h_minima(-Vinculin_distance_smooth, h)\n",
    "    Vinculin_h_markers = measure.label(Vinculin_h_min)\n",
    "    # Combine ridges and seeds\n",
    "    Vinculin_combined_markers = Vinculin_ridge_markers.copy()\n",
    "    Vinculin_offset = Vinculin_combined_markers.max() + 1\n",
    "    Vinculin_combined_markers[Vinculin_h_markers > 0] = Vinculin_h_markers[Vinculin_h_markers > 0] + Vinculin_offset\n",
    "    #Watershed\n",
    "    Vinc_ws = segmentation.watershed(-Vinculin_distance_smooth, Vinculin_combined_markers, mask=Vinculin_mask_clean)\n",
    "    # Remove small labels from watershed\n",
    "    Vinc_ws_clean = morphology.remove_small_objects(Vinc_ws,min_size=15,connectivity=1)\n",
    "    # Measure properties of FAs\n",
    "    Vinculin_props_table = measure.regionprops_table(Vinc_ws_clean, intensity_image=Vinculin_channel,\n",
    "        properties=['label', 'area', 'centroid', 'eccentricity', 'solidity', 'mean_intensity'])\n",
    "    Vinculin_df = pd.DataFrame(Vinculin_props_table)\n",
    "\n",
    "    # Save a tiff of the labelled puncta and also a csv file of the properties\n",
    "    output_dir = os.path.join(folder_dir, \"FA_labels\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    csv_filename = f\"{Name}_FA_labels.csv\"\n",
    "    csv_path = os.path.join(output_dir, csv_filename)\n",
    "    Vinculin_df.to_csv(csv_path, index=False)\n",
    "    # Note that this tiff is labels, not a binary mask, to be considered if loading into ImageJ and for future use.\n",
    "    tif_filename = f\"{Name}_FA_labels.tif\"\n",
    "    tif_path = os.path.join(output_dir, tif_filename)\n",
    "    tifffile.imwrite(tif_path, Vinc_ws_clean.astype(np.uint16))\n",
    "    \n",
    "    print(f\"{Name}: {len(MAPPER_df)} MAPPER objects, {len(Vinculin_df)} FA objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf687f03-a2f9-4f67-9dae-f95ab4a06bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Testing MAPPER segmentation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import napari\n",
    "import pyclesperanto_prototype as cle\n",
    "import napari_segment_blobs_and_things_with_membranes as nsbatwm  \n",
    "import napari_simpleitk_image_processing as nsitk\n",
    "from skimage import measure, morphology, segmentation\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "FA_sub = FAplane_Ims[1]  # shape (C, Y, X)\n",
    "CellMask = Masks[1]\n",
    "Name = Names[1]\n",
    "print(\"File:\", Name)\n",
    "print(\"Original shape:\", FA_sub.shape)\n",
    "\n",
    "MAPPER_channel = FA_sub[0, :, :] \n",
    "print(\"Selected channel shape:\", MAPPER_channel.shape)\n",
    "\n",
    "Sigma = 1\n",
    "MAPPERGaus = cle.gaussian_blur(MAPPER_channel, None, Sigma, Sigma, 0.0)\n",
    "\n",
    "Radius = 100\n",
    "MAPPERGausSubBG = nsbatwm.subtract_background(MAPPERGaus, Radius)\n",
    "MAPPERGausSubBG[MAPPERGausSubBG < 0] = 0\n",
    "\n",
    "# laplace box\n",
    "MAPPER_lbp = cle.laplace_box(MAPPERGausSubBG)\n",
    "\n",
    "# threshold huang\n",
    "MAPPERThresh = nsitk.threshold_huang(MAPPER_lbp)\n",
    "MAPPERThreshMask = MAPPERThresh*CellMask\n",
    "\n",
    "# Remove small objects\n",
    "mask_bool = MAPPERThreshMask.astype(bool)\n",
    "mask_clean_bool = morphology.remove_small_objects(mask_bool, min_size=5)\n",
    "MAPPERThreshMask_clean = mask_clean_bool.astype(MAPPERThreshMask.dtype)\n",
    "\n",
    "# Watershed puncta\n",
    "distance = ndi.distance_transform_edt(mask_clean_bool)\n",
    "distance_smooth = ndi.gaussian_filter(distance, sigma=1)\n",
    "local_maxi = morphology.local_maxima(distance_smooth, connectivity=1)\n",
    "local_maxi = local_maxi & mask_clean_bool  # ensure maxima only inside mask\n",
    "markers = measure.label(local_maxi) \n",
    "labels_ws = segmentation.watershed(\n",
    "    -distance_smooth,\n",
    "    markers,\n",
    "    mask=mask_clean_bool\n",
    ")\n",
    "\n",
    "# Measure properties of puncta\n",
    "props_table = measure.regionprops_table(\n",
    "    labels_ws,\n",
    "    intensity_image=MAPPER_channel,\n",
    "    properties=['label', 'area', 'centroid', 'eccentricity', 'solidity', 'mean_intensity']\n",
    ")\n",
    "df = pd.DataFrame(props_table)\n",
    "\n",
    "# Save a tiff of the labelled puncta and also a csv file of the properties\n",
    "output_dir = os.path.join(folder_dir, \"MAPPER_labels\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "csv_filename = f\"{Name}_MAPPER_labels.csv\"\n",
    "csv_path = os.path.join(output_dir, csv_filename)\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Note that this tiff is labels, not a binary mask, to be considered if loading into ImageJ and for future use.\n",
    "tif_filename = f\"{Name}_MAPPER_labels.tif\"\n",
    "tif_path = os.path.join(output_dir, tif_filename)\n",
    "tifffile.imwrite(tif_path, labels_ws.astype(np.uint16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e48314e7-897b-42d3-b8c5-7348d3d043bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Testing FA segmentation\n",
    "from skimage import measure, morphology, segmentation\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.filters import frangi\n",
    "import numpy as np\n",
    "import pyclesperanto_prototype as cle\n",
    "import napari_segment_blobs_and_things_with_membranes as nsbatwm  \n",
    "import napari_simpleitk_image_processing as nsitk\n",
    "\n",
    "FA_sub = FAplane_Ims[0]\n",
    "CellMask = Masks[0]\n",
    "Name = Names[0]\n",
    "\n",
    "Vinculin_channel = FA_sub[1, :, :]\n",
    "\n",
    "## Generate binary image\n",
    "# Gaussian blur\n",
    "Sigma = 1\n",
    "VincGaus = cle.gaussian_blur(Vinculin_channel, None, Sigma, Sigma, 0.0)\n",
    "# Background subtraction\n",
    "Radius = 20\n",
    "VincGausSubBG = nsbatwm.subtract_background(VincGaus, Radius)\n",
    "VincGausSubBG[VincGausSubBG < 0] = 0\n",
    "VincGausSubBG = (VincGausSubBG - VincGausSubBG.min()) / (VincGausSubBG.max() - VincGausSubBG.min())\n",
    "VincGausSubBG[VincGausSubBG < 0.1] = 0\n",
    "\n",
    "# Threshold and apply cell mask\n",
    "VincThresh = nsitk.threshold_otsu(VincGausSubBG)\n",
    "VincThreshMask = VincThresh * CellMask\n",
    "\n",
    "## Remove small objects\n",
    "mask_clean = morphology.remove_small_objects(VincThreshMask.astype(bool), min_size=5)\n",
    "\n",
    "## Watershed FAs\n",
    "distance = ndi.distance_transform_edt(mask_clean)\n",
    "distance_smooth = ndi.gaussian_filter(distance, sigma=1)\n",
    "\n",
    "# Generate ridges\n",
    "ridge = frangi(VincGausSubBG, sigmas=range(1, 7))\n",
    "\n",
    "ridge_thresh = 0.2 * ridge.max()   # tune 0.15–0.3\n",
    "ridge_seeds = ridge > ridge_thresh\n",
    "ridge_markers = measure.label(ridge_seeds)\n",
    "\n",
    "# Generate seeds\n",
    "h = 0.8\n",
    "h_min = morphology.h_minima(-distance_smooth, h)\n",
    "h_markers = measure.label(h_min)\n",
    "\n",
    "# Combine ridges and seeds\n",
    "combined_markers = ridge_markers.copy()\n",
    "offset = combined_markers.max() + 1\n",
    "combined_markers[h_markers > 0] = h_markers[h_markers > 0] + offset\n",
    "#Watershed\n",
    "Vinc_ws = segmentation.watershed(-distance_smooth,combined_markers,mask=mask_clean)\n",
    "# Remove small labels from watershed\n",
    "Vinc_ws_clean = morphology.remove_small_objects(Vinc_ws,min_size=15,connectivity=1)\n",
    "\n",
    "# Measure properties of FAs\n",
    "props_table = measure.regionprops_table(\n",
    "    Vinc_ws_clean,\n",
    "    intensity_image=Vinculin_channel,\n",
    "    properties=['label', 'area', 'centroid', 'eccentricity', 'solidity', 'mean_intensity']\n",
    ")\n",
    "df = pd.DataFrame(props_table)\n",
    "\n",
    "# Save a tiff of the labelled puncta and also a csv file of the properties\n",
    "output_dir = os.path.join(folder_dir, \"FA_labels\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "csv_filename = f\"{Name}_FA_labels.csv\"\n",
    "csv_path = os.path.join(output_dir, csv_filename)\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Note that this tiff is labels, not a binary mask, to be considered if loading into ImageJ and for future use.\n",
    "tif_filename = f\"{Name}_FA_labels.tif\"\n",
    "tif_path = os.path.join(output_dir, tif_filename)\n",
    "tifffile.imwrite(tif_path, Vinc_ws_clean.astype(np.uint16))\n",
    "\n",
    "viewer = napari.Viewer() \n",
    "viewer.add_image(Vinculin_channel, name=\"Original Vinculin\") \n",
    "viewer.add_image(VincGausSubBG, name=\"background subtracted\") \n",
    "viewer.add_labels(VincThreshMask, name='Result of Threshold') \n",
    "viewer.add_labels(Vinc_ws_clean, name=\"Watershed\") \n",
    "napari.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
