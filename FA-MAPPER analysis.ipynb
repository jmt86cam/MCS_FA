{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef89ac-2913-4058-9754-81b2c4f2260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an environment with devbio-napari installed in it.\n",
    "mamba create --name neurite-devbio-napari-env python=3.9 devbio-napari -c conda-forge\n",
    "\n",
    "# Activate the environment\n",
    "conda activate neurite-devbio-napari-env\n",
    "\n",
    "# Open Jupyter\n",
    "jupyter lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291a8d3d-7409-4ccc-a303-8f010331a531",
   "metadata": {},
   "source": [
    "### Inspect image shape ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2773f398-0014-42d0-9c46-598f8009565e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage.io import imread\n",
    "import napari\n",
    "\n",
    "# -------------------------------\n",
    "# Step 0: Pick an image to inspect\n",
    "# -------------------------------\n",
    "folder_dir = os.path.join(os.path.dirname(__file__), \"../images\")\n",
    "\n",
    "# List all TIFF images\n",
    "files = [f for f in os.listdir(folder_dir) if f.endswith(\".tif\")]\n",
    "print(f\"Found {len(files)} images.\")\n",
    "\n",
    "# Pick one image (index 0 for example)\n",
    "img_path = os.path.join(folder_dir, files[0])\n",
    "img = imread(img_path)\n",
    "print(f\"Loaded {files[0]} with shape: {img.shape}\")\n",
    "\n",
    "print(\"\\nCheck the shape above.\")\n",
    "print(\"If your image shape is (H, W, C), channel_axis = -1\")\n",
    "print(\"If your image shape is (C, H, W), channel_axis = 0\")\n",
    "channel_axis = int(input(\"Enter the channel axis index: \"))\n",
    "print(f\"Using channel_axis = {channel_axis} for this dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be769b9c-3d18-44f9-b990-54a388686177",
   "metadata": {},
   "source": [
    "### Save cell and background masks, pixel sizes, background values ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a202914-a70f-48cf-a6fd-25d469ff3306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import pandas as pd\n",
    "import napari\n",
    "from qtpy.QtWidgets import QPushButton\n",
    "\n",
    "CHANNEL1 = \"channel1\"  \n",
    "CHANNEL2 = \"channel2\"\n",
    "\n",
    "# 1. Load images\n",
    "def load_images(folder_dir):\n",
    "    files = [f for f in os.listdir(folder_dir) if f.endswith(\".tif\")]\n",
    "    ImsFP = [os.path.join(folder_dir, f) for f in files]\n",
    "    ImNames = files\n",
    "    Ims = [tifffile.imread(path) for path in ImsFP]\n",
    "    print(f\"Loaded {len(Ims)} images from {folder_dir}\")\n",
    "    return Ims, ImsFP, ImNames\n",
    "\n",
    "# 2. Extract pixel sizes\n",
    "def extract_pixel_sizes(ImsFP):\n",
    "    pixel_data = []\n",
    "    for path in ImsFP:\n",
    "        with tifffile.TiffFile(path) as tif:\n",
    "            tags = tif.pages[0].tags\n",
    "            x_res = tags[\"XResolution\"].value[0] / tags[\"XResolution\"].value[1] if \"XResolution\" in tags else None\n",
    "            y_res = tags[\"YResolution\"].value[0] / tags[\"YResolution\"].value[1] if \"YResolution\" in tags else None\n",
    "            x_size = 1/x_res if x_res else None\n",
    "            y_size = 1/y_res if y_res else None\n",
    "            pixel_area = x_size*y_size if x_size and y_size else None\n",
    "            pixel_data.append({\"file\": os.path.basename(path), \"x_size\": x_size, \"y_size\": y_size, \"pixel_area\": pixel_area})\n",
    "    return pd.DataFrame(pixel_data)\n",
    "\n",
    "# 3. Check for existing masks\n",
    "def check_existing_masks(folder_dir, file_name):\n",
    "    mask_dir = os.path.join(folder_dir, \"CellMasks\")\n",
    "    if not os.path.exists(mask_dir):\n",
    "        return None, None\n",
    "\n",
    "    base = os.path.splitext(file_name)[0]\n",
    "\n",
    "    # Cell masks\n",
    "    cell_masks = sorted([\n",
    "        os.path.join(mask_dir, f) \n",
    "        for f in os.listdir(mask_dir) \n",
    "        if f.startswith(base + \"_cell\") and f.endswith(\".tif\")\n",
    "    ])\n",
    "    # Background mask\n",
    "    bg_mask_path = os.path.join(mask_dir, f\"{base}_background.tif\")\n",
    "    if not os.path.exists(bg_mask_path):\n",
    "        bg_mask_path = None\n",
    "\n",
    "    return cell_masks, bg_mask_path\n",
    "\n",
    "# 4. Measure background from existing mask\n",
    "def measure_background_from_mask(img, bg_mask_path, file_name, bg_csv):\n",
    "    mask = tifffile.imread(bg_mask_path).astype(bool)\n",
    "    MIP = img.max(axis=0)\n",
    "\n",
    "    # MIP metrics\n",
    "    c1_vals_MIP = MIP[1][mask]\n",
    "    c2_vals_MIP = MIP[0][mask]\n",
    "    bg_c1_MIP     = np.mean(c1_vals_MIP)\n",
    "    bg_c1_MIP_med = np.median(c1_vals_MIP)\n",
    "    bg_c2_MIP     = np.mean(c2_vals_MIP)\n",
    "    bg_c2_MIP_med = np.median(c2_vals_MIP)\n",
    "\n",
    "    # Full Z-stack metrics\n",
    "    c1_vals_Z = img[:,1][..., mask].flatten()\n",
    "    c2_vals_Z = img[:,0][..., mask].flatten()\n",
    "    bg_c1_Z     = np.mean(c1_vals_Z)\n",
    "    bg_c1_Z_med = np.median(c1_vals_Z)\n",
    "    bg_c2_Z     = np.mean(c2_vals_Z)\n",
    "    bg_c2_Z_med = np.median(c2_vals_Z)\n",
    "\n",
    "    df = pd.DataFrame([[file_name, bg_c1_MIP, bg_c1_MIP_med, bg_c1_Z, bg_c1_Z_med,\n",
    "                        bg_c2_MIP, bg_c2_MIP_med, bg_c2_Z, bg_c2_Z_med]],\n",
    "                      columns=[\"file\",\n",
    "                               f\"Bg_{CHANNEL1}_MIP\", f\"Bg_{CHANNEL1}_MIP_median\",\n",
    "                               f\"Bg_{CHANNEL1}_Zmean\", f\"Bg_{CHANNEL1}_Zmedian\",\n",
    "                               f\"Bg_{CHANNEL2}_MIP\", f\"Bg_{CHANNEL2}_MIP_median\",\n",
    "                               f\"Bg_{CHANNEL2}_Zmean\", f\"Bg_{CHANNEL2}_Zmedian\"])\n",
    "    df.to_csv(bg_csv, mode='a', header=not os.path.exists(bg_csv), index=False)\n",
    "    print(f\"Saved background values for {file_name}\")\n",
    "\n",
    "# 5. Draw masks + background\n",
    "def draw_masks_and_background(img, MIP, file_name, mask_dir, bg_csv, channel_axis=0):\n",
    "    os.makedirs(mask_dir, exist_ok=True)\n",
    "    viewer = napari.view_image(MIP, name=file_name, channel_axis=channel_axis)\n",
    "\n",
    "    # Cell masks\n",
    "    mask_layer = viewer.add_shapes(name=\"Cell masks\")\n",
    "    def save_masks_on_close():\n",
    "        masks_stack = mask_layer.to_masks(MIP.shape[1:])\n",
    "        if masks_stack.shape[0] == 0:\n",
    "            print(\"No cell masks drawn, skipping save.\")\n",
    "            return\n",
    "        file_basename = os.path.splitext(file_name)[0]\n",
    "        for idx, mask in enumerate(masks_stack, start=1):\n",
    "            mask_to_save = (mask > 0).astype(np.uint8) * 255\n",
    "            tifffile.imwrite(os.path.join(mask_dir, f\"{file_basename}_cell{idx}.tif\"), mask_to_save)\n",
    "        print(f\"Saved {len(masks_stack)} masks to: {mask_dir}\")\n",
    "\n",
    "    button_masks = QPushButton(\"Save cell masks\")\n",
    "    button_masks.clicked.connect(save_masks_on_close)\n",
    "    viewer.window.add_dock_widget(button_masks)\n",
    "\n",
    "    # Background\n",
    "    bg_layer = viewer.add_shapes(name=\"Background\")\n",
    "    def save_background():\n",
    "        mask = bg_layer.to_masks(MIP.shape[1:]).max(axis=0)\n",
    "        if mask.sum() < 1:\n",
    "            print(\"No background region drawn!\")\n",
    "            return\n",
    "        mask_path = os.path.join(mask_dir, f\"{os.path.splitext(file_name)[0]}_background.tif\")\n",
    "        tifffile.imwrite(mask_path, (mask > 0).astype(np.uint8)*255)\n",
    "        print(f\"Saved background region for {file_name}\")\n",
    "\n",
    "        # MIP metrics\n",
    "        mask_bool = mask.astype(bool)\n",
    "        c1_vals_MIP = MIP[1][mask_bool]\n",
    "        c2_vals_MIP = MIP[0][mask_bool]\n",
    "        bg_c1_MIP     = np.mean(c1_vals_MIP)\n",
    "        bg_c1_MIP_med = np.median(c1_vals_MIP)\n",
    "        bg_c2_MIP     = np.mean(c2_vals_MIP)\n",
    "        bg_c2_MIP_med = np.median(c2_vals_MIP)\n",
    "\n",
    "        # Full Z-stack metrics\n",
    "        c1_vals_Z = img[:,1][..., mask_bool].flatten()\n",
    "        c2_vals_Z = img[:,0][..., mask_bool].flatten()\n",
    "        bg_c1_Z     = np.mean(c1_vals_Z)\n",
    "        bg_c1_Z_med = np.median(c1_vals_Z)\n",
    "        bg_c2_Z     = np.mean(c2_vals_Z)\n",
    "        bg_c2_Z_med = np.median(c2_vals_Z)\n",
    "\n",
    "        # Save to CSV\n",
    "        df = pd.DataFrame([[file_name, bg_c1_MIP, bg_c1_MIP_med, bg_c1_Z, bg_c1_Z_med,\n",
    "                            bg_c2_MIP, bg_c2_MIP_med, bg_c2_Z, bg_c2_Z_med]],\n",
    "                          columns=[\"file\",\n",
    "                                   f\"Bg_{CHANNEL1}_MIP\", f\"Bg_{CHANNEL1}_MIP_median\",\n",
    "                                   f\"Bg_{CHANNEL1}_Zmean\", f\"Bg_{CHANNEL1}_Zmedian\",\n",
    "                                   f\"Bg_{CHANNEL2}_MIP\", f\"Bg_{CHANNEL2}_MIP_median\",\n",
    "                                   f\"Bg_{CHANNEL2}_Zmean\", f\"Bg_{CHANNEL2}_Zmedian\"])\n",
    "        df.to_csv(bg_csv, mode='a', header=not os.path.exists(bg_csv), index=False)\n",
    "        print(f\"Saved background values for {file_name}\")\n",
    "\n",
    "    button_bg = QPushButton(\"Save background region\")\n",
    "    button_bg.clicked.connect(save_background)\n",
    "    viewer.window.add_dock_widget(button_bg)\n",
    "\n",
    "    viewer.show(block=True)\n",
    "\n",
    "# 6. Run pipeline\n",
    "def run_pipeline(folder_dir, channel_axis=0):\n",
    "    Ims, ImsFP, ImNames = load_images(folder_dir)\n",
    "    \n",
    "    pixel_csv = os.path.join(folder_dir, \"pixel_sizes.csv\")\n",
    "    bg_csv    = os.path.join(folder_dir, \"background_values.csv\")\n",
    "    \n",
    "    # Remove existing CSVs so we start fresh\n",
    "    if os.path.exists(pixel_csv):\n",
    "        os.remove(pixel_csv)\n",
    "    if os.path.exists(bg_csv):\n",
    "        os.remove(bg_csv)\n",
    "\n",
    "    # Save pixel sizes\n",
    "    pixel_df = extract_pixel_sizes(ImsFP)\n",
    "    pixel_df.to_csv(pixel_csv, index=False)\n",
    "\n",
    "    for img, name in zip(Ims, ImNames):\n",
    "        base = os.path.splitext(name)[0]\n",
    "        mask_dir = os.path.join(folder_dir, \"CellMasks\")\n",
    "        print(f\"\\n=== Processing {base} ===\")\n",
    "\n",
    "        # Check existing masks\n",
    "        cell_masks, bg_mask_path = check_existing_masks(folder_dir, base)\n",
    "\n",
    "        if bg_mask_path is not None:\n",
    "            measure_background_from_mask(img, bg_mask_path, base, bg_csv)\n",
    "            print(f\"Measured background from existing mask for {base}\")\n",
    "        else:\n",
    "            MIP = img.max(axis=0)\n",
    "            draw_masks_and_background(img, MIP, base, mask_dir, bg_csv, channel_axis=channel_axis)\n",
    "        print(f\"Finished processing {base}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_dir = r\"C:\\Users\\jonatmt\\OneDrive - Universitetet i Oslo\\Desktop\\FA MAPPER test run\"\n",
    "    run_pipeline(folder_dir, channel_axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e2e8a8-b028-428f-9bed-0afd8f32fb73",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Open each cell, save a masked cell within the bounding box, also save the cell area ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cab381-1c46-43b0-9d8b-60da8a5b8019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Extract cropped 4D cell stack + mask area + bbox area\n",
    "def extract_cell_stack(img_4d, mask_path):\n",
    "    mask = tifffile.imread(mask_path) > 0\n",
    "\n",
    "    rows, cols = np.nonzero(mask)\n",
    "    if len(rows) == 0:\n",
    "        return None, None, None, None\n",
    "\n",
    "    min_r, max_r = np.min(rows), np.max(rows)\n",
    "    min_c, max_c = np.min(cols), np.max(cols)\n",
    "\n",
    "    cropped = img_4d[:, :, min_r:max_r+1, min_c:max_c+1]\n",
    "\n",
    "    mask_area = np.sum(mask)\n",
    "    bbox_area = (max_r - min_r + 1) * (max_c - min_c + 1)\n",
    "\n",
    "    return cropped, mask_area, bbox_area, (min_r, max_r, min_c, max_c)\n",
    "\n",
    "# 2. Save cropped cell stack to TIFF\n",
    "def save_cropped_cell(cropped_stack, output_dir, base, cell_index):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    save_path = os.path.join(output_dir, f\"{base}_cell{cell_index}.tif\")\n",
    "    tifffile.imwrite(save_path, cropped_stack.astype(cropped_stack.dtype), imagej=True, metadata={'axes': 'ZCYX'})\n",
    "\n",
    "    return save_path\n",
    "\n",
    "# 3. Run pipeline\n",
    "def process_cells(folder_dir):\n",
    "    mask_dir = os.path.join(folder_dir, \"CellMasks\")\n",
    "    output_dir = os.path.join(folder_dir, \"Cells\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    csv_path = os.path.join(folder_dir, \"cell_measurements.csv\")\n",
    "    cells_list = []\n",
    "    cell_names = []\n",
    "    entries = []\n",
    "\n",
    "    # Loop over original images\n",
    "    for fname in os.listdir(folder_dir):\n",
    "        if not fname.endswith(\".tif\"):\n",
    "            continue\n",
    "\n",
    "        base = os.path.splitext(fname)[0]\n",
    "        print(f\"\\n=== Processing {base} ===\")\n",
    "\n",
    "        img_path = os.path.join(folder_dir, fname)\n",
    "        img_4d = tifffile.imread(img_path)\n",
    "\n",
    "        # Collect masks for this image\n",
    "        file_basename = os.path.splitext(os.path.basename(base))[0]\n",
    "        mask_files = sorted(\n",
    "            [f for f in os.listdir(mask_dir) if f.startswith(file_basename + \"_cell\")]\n",
    "        )\n",
    "\n",
    "        if len(mask_files) == 0:\n",
    "            print(\"No masks found for this image.\")\n",
    "            continue\n",
    "\n",
    "        for idx, mask_file in enumerate(mask_files, start=1):\n",
    "            mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "            # --- 1. Extract cropped stack ---\n",
    "            cropped, mask_area, bbox_area, bbox_coords = extract_cell_stack(img_4d, mask_path)\n",
    "\n",
    "            if cropped is None:\n",
    "                print(f\"Empty mask for {mask_file}\")\n",
    "                continue\n",
    "\n",
    "            # --- 2. Save cropped TIFF ---\n",
    "            cell_tif_path = save_cropped_cell(cropped, output_dir, file_basename, idx)\n",
    "\n",
    "\n",
    "            # --- Collect results ---\n",
    "            entries.append([\n",
    "                base,\n",
    "                f\"{file_basename}_cell{idx}.tif\",\n",
    "                mask_area,\n",
    "                bbox_area,\n",
    "                cell_tif_path,\n",
    "                mask_path\n",
    "            ])\n",
    "\n",
    "    # Save results to CSV\n",
    "    df = pd.DataFrame(\n",
    "        entries,\n",
    "        columns=[\"file\", \"cell_image\", \"mask_area\", \"bbox_area\", \"cell_tif_path\", \"mask_path\"]\n",
    "    )\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"\\nSaved measurements to: {csv_path}\")\n",
    "\n",
    "def run_cell_pipeline(folder_dir):\n",
    "    \"\"\"\n",
    "    Run AFTER mask drawing pipeline.\n",
    "    Extract each cell, save TIFF, compute areas\n",
    "    \"\"\"\n",
    "    process_cells(folder_dir)\n",
    "\n",
    "\n",
    "folder_dir =  os.path.join(os.path.dirname(__file__), \"../images\")\n",
    "run_cell_pipeline(folder_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc93c56-1cdd-4190-920c-b7e29628a0c7",
   "metadata": {},
   "source": [
    "### Manually open each cell in imageJ and make a csv file with the filename and focal plane ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ac5e04-940a-48d7-9baf-2fde6d5da856",
   "metadata": {},
   "source": [
    "### Combine all csv files into one \"all_cell_details\" csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1eea11-6fc2-4086-bba9-2ffa6adc0fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "folder_dir =  os.path.join(os.path.dirname(__file__), \"../images\")\n",
    "\n",
    "pixel_csv = os.path.join(folder_dir, \"pixel_sizes.csv\")\n",
    "bg_csv = os.path.join(folder_dir, \"background_values.csv\")\n",
    "measure_csv = os.path.join(folder_dir, \"cell_measurements.csv\")\n",
    "manual_csv = os.path.join(folder_dir, \"cell_ManualDetails.csv\")\n",
    "\n",
    "# Load the CSV files\n",
    "pixel_df = pd.read_csv(pixel_csv)\n",
    "bg_df = pd.read_csv(bg_csv)\n",
    "measure_df = pd.read_csv(measure_csv)\n",
    "manual_df = pd.read_csv(manual_csv, sep = \";\")\n",
    "\n",
    "# Merge on the \"file\" column\n",
    "merged_df1 = pd.merge(pixel_df, bg_df, on=\"file\", how=\"left\")\n",
    "\n",
    "# Merge on the \"cell_image\" column\n",
    "merged_df2 = pd.merge(measure_df, manual_df, on=\"cell_image\", how=\"left\")\n",
    "# Remove duplicated \"file\" column\n",
    "if \"file_x\" in merged_df2.columns and \"file_y\" in merged_df2.columns:\n",
    "    merged_df2[\"file\"] = merged_df2[\"file_x\"]\n",
    "    merged_df2 = merged_df2.drop(columns=[\"file_x\", \"file_y\"])\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    merged_df2,\n",
    "    merged_df1,\n",
    "    on=\"file\",\n",
    "    how=\"left\"      # keep ALL cell rows and duplicate pixel/bg data\n",
    ")\n",
    "\n",
    "# Save\n",
    "output_path = os.path.join(folder_dir, \"all_cell_details.csv\")\n",
    "merged_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946fc860-b414-4fee-87f5-a5bd11a7e682",
   "metadata": {},
   "source": [
    "### Open each image and extract only the focal adhesion plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe68d95-ba53-4f0e-8eb0-efb732f7716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tifffile\n",
    "\n",
    "folder_dir =  os.path.join(os.path.dirname(__file__), \"../images\")\n",
    "\n",
    "# 1. Load all_cell_details CSV\n",
    "cell_details_csv = os.path.join(folder_dir, \"all_cell_details.csv\")\n",
    "df_cell_details = pd.read_csv(cell_details_csv)\n",
    "df_cell_details[\"cell_image\"] = df_cell_details[\"cell_image\"].astype(str).str.strip()\n",
    "\n",
    "# 2. List all cell TIFFs\n",
    "cells_dir = os.path.join(folder_dir, \"Cells\")\n",
    "files = sorted([f for f in os.listdir(cells_dir) if f.endswith(\".tif\")])\n",
    "ImsFP = [os.path.join(cells_dir, f) for f in files]\n",
    "Ims = [tifffile.imread(path) for path in ImsFP]\n",
    "\n",
    "# 3. Capture only the FA-plane for both channels\n",
    "Faplane_list = []\n",
    "for f in files:\n",
    "    image_name = f\n",
    "    \n",
    "    # Look up FA-plane from manual CSV\n",
    "    row = cell_details[\n",
    "        (cell_details[\"cell_image\"] == image_name)\n",
    "    ]\n",
    "\n",
    "    if len(row) == 0:\n",
    "        # fallback if not found\n",
    "        Faplane_list.append(1)\n",
    "        print(f\"FA plane missing for {image_name} and defaulted to 1\")\n",
    "    else:\n",
    "        Faplane_list.append(int(row.iloc[0][\"Faplane\"]))\n",
    "\n",
    "FAplane_Ims = [\n",
    "    stack[fplane-1, :, :, :]  # subtract 1 if FA-plane in CSV is 1-based\n",
    "    for stack, fplane in zip(Ims, Faplane_list)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f3fbf-d00d-497c-82bb-e85ad72b7a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import napari\n",
    "import pyclesperanto_prototype as cle\n",
    "import napari_segment_blobs_and_things_with_membranes as nsbatwm  \n",
    "import napari_simpleitk_image_processing as nsitk             \n",
    "\n",
    "Sigma = 1\n",
    "Radius = 100\n",
    "\n",
    "segmented_images = []\n",
    "\n",
    "for Vinculin_sub in FAplane_Ims:\n",
    "\n",
    "    # pick Vinculin channel (channel 0)\n",
    "    Vinculin_sub = Vinculin_sub[1, :, :]  # shape (Y, X)\n",
    "\n",
    "    # --- Gaussian blur ---\n",
    "    VincGaus = cle.gaussian_blur(Vinculin_sub, None, Sigma, Sigma, 0.0)\n",
    "\n",
    "    # --- Subtract background ---\n",
    "    VincGausSubBG = nsbatwm.subtract_background(VincGaus, Radius)\n",
    "\n",
    "    # --- Remove NaN values for histogram ---\n",
    "    #Vinc_filtered_data = VincGausSubBG[~np.isnan(VincGausSubBG)]\n",
    "\n",
    "    # --- Percentiles ---\n",
    "    #Vinclower_percentile = np.percentile(Vinc_filtered_data, 1)\n",
    "    #Vincupper_percentile = np.percentile(Vinc_filtered_data, 99.95)\n",
    "\n",
    "    # --- Clip ---\n",
    "    #filtered_data_clipped = np.clip(VincGausSubBG, Vinclower_percentile, Vincupper_percentile)\n",
    "    #filtered_data_clipped[np.isnan(filtered_data_clipped)] = -1\n",
    "\n",
    "    # --- Threshold ---\n",
    "    VincThresh = nsitk.threshold_renyi_entropy(VincGausSubBG)\n",
    "\n",
    "    segmented_images.append(VincThresh)\n",
    "\n",
    "\n",
    "# --- Display all segmented images in napari ---\n",
    "viewer = napari.Viewer()\n",
    "for i, img in enumerate(segmented_images, start=1):\n",
    "    viewer.add_image(img, name=f\"Segmented {i}\")\n",
    "napari.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf687f03-a2f9-4f67-9dae-f95ab4a06bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Testing MAPPER segmentation\n",
    "\n",
    "import numpy as np\n",
    "import napari\n",
    "import pyclesperanto_prototype as cle\n",
    "import napari_segment_blobs_and_things_with_membranes as nsbatwm  \n",
    "import napari_simpleitk_image_processing as nsitk\n",
    "\n",
    "from skimage.filters import threshold_sauvola\n",
    "\n",
    "Vinculin_sub = FAplane_Ims[4]  # shape (1, 2, Y, X) in your case\n",
    "\n",
    "print(\"Original shape:\", Vinculin_sub.shape)\n",
    "\n",
    "MAPPER_channel = Vinculin_sub[0, :, :]  # shape (Y, X)\n",
    "print(\"Selected Vinculin channel shape:\", Vinculin_channel.shape)\n",
    "\n",
    "Sigma = 1\n",
    "MAPPERGaus = cle.gaussian_blur(MAPPER_channel, None, Sigma, Sigma, 0.0)\n",
    "\n",
    "Radius = 100\n",
    "MAPPERGausSubBG = nsbatwm.subtract_background(MAPPERGaus, Radius)\n",
    "MAPPERGausSubBG[MAPPERGausSubBG < 0] = 0\n",
    "\n",
    "#MAPPERThresh = nsitk.threshold_renyi_entropy(MAPPERGausSubBG) ### consider doing other thresholding\n",
    "img = np.asarray(MAPPERGausSubBG)  # convert from cle/sitk to numpy\n",
    "\n",
    "window = 25   # try 15â€“45 depending on puncta size\n",
    "k = 0.5       # Sauvola sensitivity parameter\n",
    "\n",
    "sauvola_thresh = threshold_sauvola(img, window_size=window, k=k)\n",
    "MAPPERThresh = img > sauvola_thresh\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(MAPPER_channel, name=\"Original MAPPER\")\n",
    "viewer.add_image(MAPPERGaus, name=\"Gaussian blurred\")\n",
    "viewer.add_image(MAPPERGausSubBG, name=\"Background subtracted\")\n",
    "viewer.add_image(MAPPERThresh, name=\"Segmented (Renyi)\")\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8da46b-3b95-471b-bff2-a72f03cc346f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Testing FA segmentation\n",
    "\n",
    "### thoughts on improvement are to subtract background, try different threshold algorthims and watershed the FAs.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import napari\n",
    "import pyclesperanto_prototype as cle\n",
    "import napari_segment_blobs_and_things_with_membranes as nsbatwm  \n",
    "import napari_simpleitk_image_processing as nsitk   \n",
    "\n",
    "Vinculin_sub = FAplane_Ims[4]  # shape (1, 2, Y, X) in your case\n",
    "\n",
    "print(\"Original shape:\", Vinculin_sub.shape)\n",
    "\n",
    "Vinculin_channel = Vinculin_sub[1, :, :]  # shape (Y, X)\n",
    "print(\"Selected Vinculin channel shape:\", Vinculin_channel.shape)\n",
    "\n",
    "Sigma = 1\n",
    "VincGaus = cle.gaussian_blur(Vinculin_channel, None, Sigma, Sigma, 0.0)\n",
    "\n",
    "Radius = 100\n",
    "VincGausSubBG = nsbatwm.subtract_background(VincGaus, Radius)\n",
    "VincGausSubBG[VincGausSubBG < 0] = 0\n",
    "\n",
    "VincThresh = nsitk.threshold_renyi_entropy(VincGausSubBG) ### consider doing other thresholding\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(Vinculin_channel, name=\"Original Vinculin\")\n",
    "viewer.add_image(VincGaus, name=\"Gaussian blurred\")\n",
    "viewer.add_image(VincGausSubBG, name=\"Background subtracted\")\n",
    "viewer.add_image(VincThresh, name=\"Segmented (Renyi)\")\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a0e331-5ee0-4c00-b310-4510a8f73c5d",
   "metadata": {},
   "source": [
    "#### Old code that might have a use ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa9a112-93ac-49ad-9a4b-819a3e60665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "import napari\n",
    "from PyQt5.QtWidgets import QPushButton\n",
    "\n",
    "# ==========================\n",
    "# 1. Load TIFF images\n",
    "# ==========================\n",
    "def load_images(folder_dir):\n",
    "    files = [f for f in os.listdir(folder_dir) if f.endswith(\".tif\")]\n",
    "    ImsFP = [os.path.join(folder_dir, f) for f in files]\n",
    "    ImNames = files\n",
    "    Ims = [imread(path) for path in ImsFP]\n",
    "    print(f\"Loaded {len(Ims)} images from {folder_dir}\")\n",
    "    return Ims, ImsFP, ImNames\n",
    "\n",
    "# ==========================\n",
    "# 2. Pixel size extraction\n",
    "# ==========================\n",
    "def extract_pixel_sizes(ImsFP):\n",
    "    pixel_data = []\n",
    "    for path in ImsFP:\n",
    "        with tifffile.TiffFile(path) as tif:\n",
    "            tags = tif.pages[0].tags\n",
    "            x_res = tags[\"XResolution\"].value[0] / tags[\"XResolution\"].value[1] if \"XResolution\" in tags else None\n",
    "            y_res = tags[\"YResolution\"].value[0] / tags[\"YResolution\"].value[1] if \"YResolution\" in tags else None\n",
    "            x_size = 1 / x_res if x_res else None\n",
    "            y_size = 1 / y_res if y_res else None\n",
    "            area = x_size * y_size if x_size and y_size else None\n",
    "            pixel_data.append({\n",
    "                \"file\": os.path.basename(path),\n",
    "                \"x_size\": x_size, \"y_size\": y_size, \"area\": area\n",
    "            })\n",
    "    return pd.DataFrame(pixel_data)\n",
    "\n",
    "# ==========================\n",
    "# 3. Draw cell masks + background\n",
    "# ==========================\n",
    "def draw_masks_and_background(img, file_name, mask_dir, bg_csv):\n",
    "    os.makedirs(mask_dir, exist_ok=True)\n",
    "    viewer = napari.view_image(img, name=file_name)\n",
    "\n",
    "    # ---- Cell masks ----\n",
    "    mask_layer = viewer.add_shapes(name=\"Cell masks\")\n",
    "\n",
    "    def save_masks():\n",
    "        masks = mask_layer.to_masks(img.shape[:2])\n",
    "        for i, mask in enumerate(masks):\n",
    "            mask_path = os.path.join(mask_dir, f\"{file_name}_cell{i+1}.tif\")\n",
    "            tifffile.imwrite(mask_path, (mask > 0).astype(np.uint8) * 255)\n",
    "        print(f\"Saved {len(masks)} cell masks for {file_name}\")\n",
    "\n",
    "    button_masks = QPushButton(\"Save cell masks\")\n",
    "    button_masks.clicked.connect(save_masks)\n",
    "    viewer.window.add_dock_widget(button_masks)\n",
    "\n",
    "    # ---- Background ----\n",
    "    bg_layer = viewer.add_shapes(name=\"Background\")\n",
    "\n",
    "    def save_background():\n",
    "        mask = bg_layer.to_masks(img.shape[:2]).squeeze()\n",
    "        if mask.sum() == 0:\n",
    "            print(\"No background region drawn!\")\n",
    "            return\n",
    "        ERmean = np.mean(img[:, :, 1][mask > 0])\n",
    "        Lysmean = np.mean(img[:, :, 0][mask > 0])\n",
    "        df = pd.DataFrame([[file_name, ERmean, Lysmean]],\n",
    "                          columns=[\"file\", \"ER_CN\", \"Lys_CN\"])\n",
    "        df.to_csv(bg_csv, mode='a', header=not os.path.exists(bg_csv), index=False)\n",
    "        print(f\"Saved background values for {file_name}\")\n",
    "\n",
    "    button_bg = QPushButton(\"Save background region\")\n",
    "    button_bg.clicked.connect(save_background)\n",
    "    viewer.window.add_dock_widget(button_bg)\n",
    "\n",
    "    # ---- Block until window closed ----\n",
    "    viewer.show(block=True)\n",
    "    napari.run()\n",
    "\n",
    "# ==========================\n",
    "# 4. Draw ER sheets per cell\n",
    "# ==========================\n",
    "def draw_ersheets_per_cell(img, file_name, mask_path, output_dir, cell_index):\n",
    "    m = imread(mask_path)\n",
    "    rows, cols = np.nonzero(m)\n",
    "    min_r, max_r = np.min(rows), np.max(rows)\n",
    "    min_c, max_c = np.min(cols), np.max(cols)\n",
    "\n",
    "    cell_crop = img[min_r:max_r+1, min_c:max_c+1, :]\n",
    "    mask_crop = m[min_r:max_r+1, min_c:max_c+1]\n",
    "\n",
    "    viewer = napari.view_image(cell_crop, name=f\"{file_name}_cell{cell_index}\")\n",
    "    shapes_layer = viewer.add_shapes(name=\"ER sheets\")\n",
    "\n",
    "    def save_sheets():\n",
    "        mask = shapes_layer.to_masks(cell_crop.shape[:2]).max(axis=0)\n",
    "        mask = mask & (mask_crop > 0)\n",
    "        out_path = os.path.join(output_dir, f\"{file_name}_cell{cell_index}_sheets.tif\")\n",
    "        tifffile.imwrite(out_path, (mask > 0).astype(np.uint8) * 255)\n",
    "        print(f\"Saved ER sheets mask for cell {cell_index}\")\n",
    "\n",
    "    button = QPushButton(\"Save ER sheets mask\")\n",
    "    button.clicked.connect(save_sheets)\n",
    "    viewer.window.add_dock_widget(button)\n",
    "    \n",
    "    viewer.show(block=True)\n",
    "    napari.run()  # wait until user closes\n",
    "\n",
    "# ==========================\n",
    "# 5. Main pipeline\n",
    "# ==========================\n",
    "def run_pipeline(folder_dir):\n",
    "    Ims, ImsFP, ImNames = load_images(folder_dir)\n",
    "    pixel_df = extract_pixel_sizes(ImsFP)\n",
    "    pixel_df.to_csv(os.path.join(folder_dir, \"pixel_sizes.csv\"), index=False)\n",
    "\n",
    "    bg_csv = os.path.join(folder_dir, \"background_values.csv\")\n",
    "\n",
    "    for img, name in zip(Ims, ImNames):\n",
    "        base = os.path.splitext(name)[0]\n",
    "        mask_dir = os.path.join(folder_dir, \"CellMasks\")\n",
    "\n",
    "        print(f\"\\n=== Processing {base} ===\")\n",
    "\n",
    "        # Step 1 + 2: Draw masks + background (single viewer)\n",
    "        draw_masks_and_background(img, base, mask_dir, bg_csv)\n",
    "\n",
    "        # Step 3: For each saved cell mask, draw ER sheets in separate viewers\n",
    "        mask_files = [f for f in os.listdir(mask_dir) if f.startswith(base + \"_cell\")]\n",
    "        mask_files.sort()\n",
    "        for idx, f in enumerate(mask_files, start=1):\n",
    "            draw_ersheets_per_cell(img, base, os.path.join(mask_dir, f), mask_dir, idx)\n",
    "\n",
    "# ==========================\n",
    "# Run the pipeline\n",
    "# ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    folder_dir =  os.path.join(os.path.dirname(__file__), \"../images\")\n",
    "    run_pipeline(folder_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c23158a-5f0e-41b6-8f56-7061afaa02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "import napari\n",
    "from PyQt5.QtWidgets import QPushButton\n",
    "\n",
    "# ==========================\n",
    "# 1. Load TIFF images\n",
    "# ==========================\n",
    "def load_images(folder_dir):\n",
    "    files = [f for f in os.listdir(folder_dir) if f.endswith(\".tif\")]\n",
    "    ImsFP = [os.path.join(folder_dir, f) for f in files]\n",
    "    ImNames = files\n",
    "    Ims = [imread(path) for path in ImsFP]\n",
    "    print(f\"Loaded {len(Ims)} images from {folder_dir}\")\n",
    "    return Ims, ImsFP, ImNames\n",
    "\n",
    "# ==========================\n",
    "# 2. Pixel size extraction\n",
    "# ==========================\n",
    "def extract_pixel_sizes(ImsFP):\n",
    "    pixel_data = []\n",
    "    for path in ImsFP:\n",
    "        with tifffile.TiffFile(path) as tif:\n",
    "            tags = tif.pages[0].tags\n",
    "            x_res = tags[\"XResolution\"].value[0] / tags[\"XResolution\"].value[1] if \"XResolution\" in tags else None\n",
    "            y_res = tags[\"YResolution\"].value[0] / tags[\"YResolution\"].value[1] if \"YResolution\" in tags else None\n",
    "            x_size = 1/x_res if x_res else None\n",
    "            y_size = 1/y_res if y_res else None\n",
    "            area = x_size*y_size if x_size and y_size else None\n",
    "            pixel_data.append({\"file\": os.path.basename(path), \"x_size\": x_size, \"y_size\": y_size, \"area\": area})\n",
    "    return pd.DataFrame(pixel_data)\n",
    "\n",
    "# ==========================\n",
    "# 3. Draw cell masks\n",
    "# ==========================\n",
    "def draw_cell_masks(image, file_name, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    viewer = napari.view_image(image)\n",
    "    shapes_layer = viewer.add_shapes()\n",
    "\n",
    "    def save_masks():\n",
    "        masks = shapes_layer.to_masks(image.shape[:2])\n",
    "        for i, mask in enumerate(masks):\n",
    "            mask_path = os.path.join(output_dir, f\"{file_name}_cell{i+1}.tif\")\n",
    "            tifffile.imwrite(mask_path, (mask>0).astype(np.uint8)*255)\n",
    "        print(f\"Saved {len(masks)} cell masks for {file_name}\")\n",
    "\n",
    "    button = QPushButton('Save cell masks')\n",
    "    button.clicked.connect(save_masks)\n",
    "    viewer.window.add_dock_widget(button)\n",
    "    napari.run()\n",
    "\n",
    "# ==========================\n",
    "# 4. Draw background region\n",
    "# ==========================\n",
    "def draw_background_region(image, file_name, output_csv):\n",
    "    viewer = napari.view_image(image)\n",
    "    shapes_layer = viewer.add_shapes()\n",
    "\n",
    "    def save_background():\n",
    "        mask = shapes_layer.to_masks(image.shape[:2]).squeeze()\n",
    "        ERmean = np.mean(image[:,:,1][mask>0])\n",
    "        Lysmean = np.mean(image[:,:,0][mask>0])\n",
    "        df = pd.DataFrame([[file_name, ERmean, Lysmean]], columns=[\"file\",\"ER_CN\",\"Lys_CN\"])\n",
    "        df.to_csv(output_csv, mode='a', header=not os.path.exists(output_csv), index=False)\n",
    "        print(f\"Saved background values for {file_name}\")\n",
    "\n",
    "    button = QPushButton('Save background region')\n",
    "    button.clicked.connect(save_background)\n",
    "    viewer.window.add_dock_widget(button)\n",
    "    napari.run()\n",
    "\n",
    "# ==========================\n",
    "# 5. Draw ER sheets for each cell\n",
    "# ==========================\n",
    "def draw_ERsheets(CellsList, MasksListBB, file_name, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    ERsheetsList = []\n",
    "    for i, cell in enumerate(CellsList):\n",
    "        viewer = napari.view_image(cell, rgb=False, channel_axis=-1, colormap=['magenta','green','blue'])\n",
    "        shapes_layer = viewer.add_shapes()\n",
    "\n",
    "        def save_sheets():\n",
    "            mask = shapes_layer.to_masks(cell.shape[:2]).max(axis=0)\n",
    "            mask = mask & (MasksListBB[i]>0)\n",
    "            mask_path = os.path.join(output_dir, f\"{file_name}_cell{i+1}_sheets.tif\")\n",
    "            tifffile.imwrite(mask_path, (mask>0).astype(np.uint8)*255)\n",
    "            print(f\"Saved ER sheets mask for cell {i+1}\")\n",
    "\n",
    "        button = QPushButton('Save ER sheets mask')\n",
    "        button.clicked.connect(save_sheets)\n",
    "        viewer.window.add_dock_widget(button)\n",
    "        napari.run()\n",
    "        ERsheetsList.append(mask)\n",
    "    return ERsheetsList\n",
    "\n",
    "# ==========================\n",
    "# 6. Main pipeline\n",
    "# ==========================\n",
    "def run_pipeline(folder_dir):\n",
    "    Ims, ImsFP, ImNames = load_images(folder_dir)\n",
    "    pixel_df = extract_pixel_sizes(ImsFP)\n",
    "    pixel_df.to_csv(os.path.join(folder_dir, \"pixel_sizes.csv\"), index=False)\n",
    "\n",
    "    bg_csv = os.path.join(folder_dir, \"background_values.csv\")\n",
    "\n",
    "    for img, name in zip(Ims, ImNames):\n",
    "        base = os.path.splitext(name)[0]\n",
    "        mask_dir = os.path.join(folder_dir, \"CellMasks\")\n",
    "\n",
    "        # Step 1: Cell masks\n",
    "        draw_cell_masks(img, base, mask_dir)\n",
    "\n",
    "        # Step 2: Background region\n",
    "        MaxImCombine = np.amax(img, axis=2)\n",
    "        draw_background_region(MaxImCombine, base, bg_csv)\n",
    "\n",
    "        # Step 3: Apply cell masks for ER sheets\n",
    "        MasksList = [imread(os.path.join(mask_dir,f)) for f in os.listdir(mask_dir) if f.startswith(base+\"_cell\")]\n",
    "        CellsList, MasksListBB = [], []\n",
    "        for m in MasksList:\n",
    "            rows, cols = np.nonzero(m)\n",
    "            min_r, max_r = np.min(rows), np.max(rows)\n",
    "            min_c, max_c = np.min(cols), np.max(cols)\n",
    "            MasksListBB.append(m[min_r:max_r+1, min_c:max_c+1])\n",
    "            CellsList.append(img[min_r:max_r+1, min_c:max_c+1, :])\n",
    "\n",
    "        # Step 4: ER sheets\n",
    "        draw_ERsheets(CellsList, MasksListBB, base, mask_dir)\n",
    "\n",
    "# ==========================\n",
    "# Run the pipeline\n",
    "# ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    folder_dir =  os.path.join(os.path.dirname(__file__), \"../images\")\n",
    "    run_pipeline(folder_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a32ff4-65e6-403d-9f27-c19b0b4cf475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile\n",
    "from skimage.io import imread\n",
    "from skimage.morphology import h_maxima, remove_small_objects, disk, white_tophat\n",
    "from skimage.filters import gaussian, threshold_otsu, laplace, median, threshold_local\n",
    "from skimage import measure\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed, find_boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "import napari_segment_blobs_and_things_with_membranes as nsbatwm\n",
    "import pyclesperanto_prototype as cle\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from skimage import morphology\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import textwrap\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "## Functions\n",
    "\n",
    "def load_cell_masks(mask_dir, base_name):\n",
    "    MasksList = []\n",
    "    for f in os.listdir(mask_dir):\n",
    "        if f.startswith(base_name + '_cell') and f.endswith('.tif') and '_sheets' not in f:\n",
    "            MasksList.append(imread(os.path.join(mask_dir, f))>0)\n",
    "    return MasksList\n",
    "\n",
    "\n",
    "def load_ERsheets_masks(mask_dir, base_name, num_cells):\n",
    "    ERsheetsList = []\n",
    "    for i in range(1, num_cells+1):\n",
    "        f = os.path.join(mask_dir, f\"{base_name}_cell{i}_sheets.tif\")\n",
    "        ERsheetsList.append(imread(f)>0)\n",
    "    return ERsheetsList\n",
    "\n",
    "def pearson_correlation_coefficient(image1, image2):\n",
    "    return np.corrcoef(image1.ravel(), image2.ravel())[0, 1]\n",
    "\n",
    "def spearman_correlation_coefficient(image1, image2):\n",
    "    return spearmanr(image1.ravel(), image2.ravel()).correlation\n",
    "\n",
    "def kendall_tau(image1, image2):\n",
    "    return kendalltau(image1.ravel(), image2.ravel()).correlation\n",
    "\n",
    "def manders_coefficients(image1, image2):\n",
    "    image1 = image1.astype(np.float64)\n",
    "    image2 = image2.astype(np.float64)\n",
    "    M1 = np.sum(image1[image2 > 0]) / np.sum(image1) if np.sum(image1) > 0 else 0.0\n",
    "    M2 = np.sum(image2[image1 > 0]) / np.sum(image2) if np.sum(image2) > 0 else 0.0\n",
    "    return M1, M2\n",
    "\n",
    "def overlap_coefficient(image1, image2):\n",
    "    image1 = image1.astype(np.float64)\n",
    "    image2 = image2.astype(np.float64)\n",
    "    return np.sum(np.minimum(image1, image2)) / np.sqrt(np.sum(image1) * np.sum(image2))\n",
    "\n",
    "def jaccard_index(mask1, mask2):\n",
    "    intersection = np.logical_and(mask1, mask2).sum()\n",
    "    union = np.logical_or(mask1, mask2).sum()\n",
    "    return intersection / union if union != 0 else 0.0\n",
    "\n",
    "def dice_coefficient(mask1, mask2):\n",
    "    intersection = np.logical_and(mask1, mask2).sum()\n",
    "    denom = mask1.sum() + mask2.sum()\n",
    "    return (2.0 * intersection / denom) if denom != 0 else 0.0\n",
    "\n",
    "def compute_all_coefficients(img1, img2, mask1, mask2, region='All', ch1=1, ch2=2):\n",
    "    # Intensity-based metrics\n",
    "    pearson = pearson_correlation_coefficient(img1, img2)\n",
    "    spearman = spearman_correlation_coefficient(img1, img2)\n",
    "    kendall = kendall_tau(img1, img2)\n",
    "    manders_int = manders_coefficients(img1, img2)\n",
    "    overlap = overlap_coefficient(img1, img2)\n",
    "\n",
    "    # Mask-based metrics\n",
    "    jaccard = jaccard_index(mask1, mask2)\n",
    "    dice = dice_coefficient(mask1, mask2)\n",
    "    manders_mask = manders_coefficients(mask1, mask2)\n",
    "\n",
    "    return {\n",
    "        'Region': region,\n",
    "        'Channel 1': ch1,\n",
    "        'Channel 2': ch2,\n",
    "        # Intensity-based\n",
    "        'Pearson': pearson,\n",
    "        'Spearman': spearman,\n",
    "        'Kendall Tau': kendall,\n",
    "        'Manders Ch1 with Ch2 (Intensity)': manders_int[0],\n",
    "        'Manders Ch2 with Ch1 (Intensity)': manders_int[1],\n",
    "        'Overlap Coefficient': overlap,\n",
    "        # Mask-based\n",
    "        'Dice Coefficient': dice,\n",
    "        'Jaccard Index': jaccard,\n",
    "        'Manders Ch1 with Ch2 (Mask)': manders_mask[0],\n",
    "        'Manders Ch2 with Ch1 (Mask)': manders_mask[1],\n",
    "    }\n",
    "\n",
    "## Automated pipeline\n",
    "\n",
    "def automated_analysis(folder_dir):\n",
    "    # Load lists of images\n",
    "    ImNames = [f for f in os.listdir(folder_dir) if f.endswith('.tif')]\n",
    "    ImsFP = [os.path.join(folder_dir, f) for f in ImNames]\n",
    "\n",
    "    # Load pixel sizes and background\n",
    "    #pixel_sizes = pd.read_csv(os.path.join(folder_dir, 'pixel_sizes.csv'), index_col=False)\n",
    "    #background = pd.read_csv(os.path.join(folder_dir, 'background_values.csv'), index_col=False)\n",
    "\n",
    "    for CurrentIm, (ImPath, file_name) in enumerate(zip(ImsFP, ImNames)):\n",
    "        base = os.path.splitext(file_name)[0]\n",
    "        print(f\"Processing image {CurrentIm+1}/{len(ImsFP)}: {file_name}\")\n",
    "\n",
    "        Im = imread(ImPath)\n",
    "        mask_dir = os.path.join(folder_dir, 'CellMasks')\n",
    "\n",
    "        # Load masks\n",
    "        MasksList = load_cell_masks(mask_dir, base)\n",
    "        CellsList, MasksListBB = [], []\n",
    "        for m in MasksList:\n",
    "            rows, cols = np.nonzero(m)\n",
    "            min_r, max_r = np.min(rows), np.max(rows)\n",
    "            min_c, max_c = np.min(cols), np.max(cols)\n",
    "            MasksListBB.append(m[min_r:max_r+1, min_c:max_c+1])\n",
    "            CellsList.append(Im[min_r:max_r+1, min_c:max_c+1, :])\n",
    "\n",
    "        ERsheetsList = load_ERsheets_masks(mask_dir, base, len(CellsList))\n",
    "\n",
    "        # Pixel and background\n",
    "        #pixel_info = pixel_sizes[pixel_sizes.file==file_name].iloc[0]\n",
    "        #x_pixel_size = pixel_info.x_size\n",
    "        #y_pixel_size = pixel_info.y_size\n",
    "        #xy_pixel_area = pixel_info.area\n",
    "        #bg_info = background[background.file==file_name].iloc[0]\n",
    "        #ER_CN = bg_info.ER_CN\n",
    "        #Lys_CN = bg_info.Lys_CN\n",
    "        ER_CN = 104\n",
    "        Lys_CN = 104\n",
    "\n",
    "        for CurrentCell, substack in enumerate(CellsList):\n",
    "            print(f\"  Analyzing cell {CurrentCell+1}/{len(CellsList)}\")\n",
    "\n",
    "            # --- Analysis steps ---\n",
    "            # Extract channels\n",
    "            ER = substack[:,:,1]\n",
    "            Lys = substack[:,:,0]\n",
    "            Rab18 = substack[:,:,2]\n",
    "            #CellMask = MasksListBB[CurrentCell]\n",
    "            #CellMask = CellMask.astype(int)\n",
    "            CellMask = np.clip(MasksListBB[CurrentCell], 0, 1)\n",
    "            #ERsheets = ERsheetsList[CurrentCell]\n",
    "            #ERsheets = ERsheets.astype(int)\n",
    "            ERsheets = np.clip(ERsheetsList[CurrentCell], 0, 1)\n",
    "            CellMask_bool = CellMask > 0\n",
    "            ERsheets_bool = ERsheets > 0\n",
    "\n",
    "            # ER background subtraction and threshold\n",
    "            ObjectSize = 5\n",
    "            ER_sub = np.copy(ER)\n",
    "            for i in range(ER_sub.shape[0]):\n",
    "                for j in range(ER_sub.shape[1]):\n",
    "                    pixel_value = ER_sub[i, j]\n",
    "                    new_value = max(int(pixel_value - (0.9 * ER_CN)), 0)  # prevent negative\n",
    "                    ER_sub[i, j] = new_value\n",
    "            # Mask out regions outside the cell (after filtering!)\n",
    "            ER_masked = np.where(CellMask == 1, ER_sub, 0)\n",
    "\n",
    "            # Apply Otsu thresholding to the masked filtered image\n",
    "            threshold_val = threshold_otsu(ER_masked)\n",
    "            ERThresh = ER_masked > threshold_val\n",
    "            \n",
    "            ERThresh_clean = remove_small_objects(ERThresh, min_size=ObjectSize)\n",
    "\n",
    "            # Lysosome processing\n",
    "\n",
    "            # --- Preprocessing ---\n",
    "            # Subtract camera/ER background\n",
    "            Lys_sub = np.maximum(Lys - 0.9 * Lys_CN, 0)\n",
    "\n",
    "            # Median filter to reduce salt-and-pepper noise\n",
    "            Lys_denoised = median(Lys_sub, disk(1))  # adjust radius if needed\n",
    "\n",
    "            # Optional top-hat for small bright lysosomes\n",
    "            Lys_enhanced = Lys_denoised - ndi.grey_opening(Lys_denoised, size=(15,15))\n",
    "            Lys_enhanced = np.clip(Lys_enhanced, 0, None)\n",
    "\n",
    "            # Normalize 0-1\n",
    "            Lys_norm = (Lys_enhanced - Lys_enhanced.min()) / (Lys_enhanced.max() - Lys_enhanced.min() + 1e-9)\n",
    "\n",
    "            # --- Adaptive thresholding ---\n",
    "            block_size = 25  # local window size, adjust as needed\n",
    "            local_thresh = threshold_local(Lys_norm, block_size, offset=-0.05)  # slightly lower to include dim lysosomes\n",
    "            Lys_thresh = (Lys_norm > local_thresh) * CellMask\n",
    "\n",
    "            # --- Remove tiny noise ---\n",
    "            MinBlobSize = 5\n",
    "            Lys_thresh = (Lys_norm > local_thresh) & (CellMask > 0)  # boolean mask\n",
    "            Lys_thresh = remove_small_objects(Lys_thresh, min_size=5)\n",
    "\n",
    "            # --- Optional watershed for clusters ---\n",
    "            distance = ndi.distance_transform_edt(Lys_thresh)\n",
    "            coords = peak_local_max(distance, labels=Lys_thresh, min_distance=1)  # small distance to detect small peaks\n",
    "            local_maxi = np.zeros_like(distance, dtype=bool)\n",
    "            if coords.size > 0:\n",
    "                local_maxi[tuple(coords.T)] = True\n",
    "            markers = label(local_maxi)[0]\n",
    "            if np.max(markers) > 0:\n",
    "                Lys_watershed = watershed(-distance, markers, mask=Lys_thresh)\n",
    "            else:\n",
    "                Lys_watershed = Lys_thresh.astype(np.uint16)\n",
    "\n",
    "            # --- Size filtering ---\n",
    "            props = regionprops(Lys_watershed)\n",
    "            Lys_final = np.zeros_like(Lys_watershed, dtype=np.uint16)\n",
    "            if len(props) > 0:\n",
    "                areas = [p.area for p in props]\n",
    "                cutoff = max(5, np.percentile(areas, 20))  # remove smallest 20%\n",
    "                for p in props:\n",
    "                    area = p.area\n",
    "                    perimeter = max(p.perimeter, 1)\n",
    "                    if area >= cutoff:\n",
    "                        Lys_final[Lys_watershed == p.label] = p.label\n",
    "                        \n",
    "            Lys_final = (Lys_final > 0).astype(np.uint8)\n",
    "\n",
    "\n",
    "            ## Prepare PDF with multiple pages\n",
    "            # Create a PdfPages object to save multiple figures into a single PDF file\n",
    "            save_file_name = f\"{file_name}_Cell{CurrentCell + 1}\"\n",
    "            pdf_path = os.path.join(folder_dir, f\"{save_file_name}.pdf\")\n",
    "            pdf_pages = PdfPages(pdf_path)\n",
    "\n",
    "            # Page 1: Summary\n",
    "            fig, axs = plt.subplots(ncols=2, nrows=4, figsize=(10,20))\n",
    "            axs = axs.ravel()\n",
    "            for ax, data, title in zip(axs, [CellMask, ERsheets, Lys, Lys_final, ER, ERThresh_clean, Rab18],\n",
    "                                       ['Cell Mask','ER sheets mask','Original Lys','Thresholded Lys','Original ER','Thresholded ER','Rab18']):\n",
    "                ax.imshow(data,cmap='gray')\n",
    "                ax.set_title(title)\n",
    "                ax.axis('off')\n",
    "            #fig.text(0.5, 0.01, f\"Pixel sizes x={x_pixel_size}um, y={y_pixel_size}um, area={xy_pixel_area}um^2\", ha='center')\n",
    "            pdf_pages.savefig(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "            # Page 2: Lysosome processing\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "            ax[0].imshow(Lys, cmap='gray')\n",
    "            ax[0].set_title(\"Original Lysosome Channel\")\n",
    "            ax[0].axis('off')\n",
    "\n",
    "            boundaries = find_boundaries(Lys_final)\n",
    "            overlay = np.dstack([Lys]*3)\n",
    "            overlay[boundaries, 0] = 255  # red boundaries\n",
    "            ax[1].imshow(overlay.astype(np.uint8))\n",
    "            ax[1].set_title(f\"LoG + Watershed + MinSize={int(MinBlobSize)} px\")\n",
    "            ax[1].axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            pdf_pages.savefig(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "            # Page 3: ER processing\n",
    "            fig, axs = plt.subplots(ncols=2, nrows=2, figsize=(15,10))\n",
    "            fig.suptitle(textwrap.fill('ER channel', width=40), fontsize=16, fontweight='bold')\n",
    "            ER_imgs = [ER, ER_sub, ERThresh, ERThresh_clean]\n",
    "            ER_titles = [\n",
    "                'Original ER image',\n",
    "                f'Background subtracted ER (value = {ER_CN})',\n",
    "                'Otsu Thresholded ER',\n",
    "                f'Otsu Thresholded and small object cleaned ER (size = 5 px)'\n",
    "            ]\n",
    "            for i, (data, title) in enumerate(zip(ER_imgs, ER_titles)):\n",
    "                ax = axs[i//2, i%2]\n",
    "                ax.imshow(data, cmap='gray')\n",
    "                ax.set_title(title)\n",
    "                ax.axis('off')\n",
    "            pdf_pages.savefig(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "            pdf_pages.close()\n",
    "\n",
    "            ## --- Region properties & Co-localisation ---\n",
    "            Lys_Ana = nsbatwm.connected_component_labeling(Lys_final, False)\n",
    "            Lys_props = measure.regionprops(Lys_Ana, intensity_image=Lys)\n",
    "            \n",
    "            def get_region_property_values(region, property_names):\n",
    "                property_values = {}\n",
    "                for prop_name in property_names:\n",
    "                    prop_value = getattr(region, prop_name, None)\n",
    "                    if ' ' not in str(prop_value):\n",
    "                        property_values[prop_name] = prop_value\n",
    "                return property_values\n",
    "\n",
    "            # Only if there are any regions\n",
    "            if len(Lys_props) > 0:\n",
    "                Lys_property_names = [attr for attr in dir(Lys_props[0]) if not attr.startswith('_')]\n",
    "                Lys_region_data = [get_region_property_values(region, Lys_property_names) for region in Lys_props]\n",
    "            else:\n",
    "                Lys_region_data = []\n",
    "\n",
    "            Lys_region_data_augmented = []\n",
    "\n",
    "            for i, region in enumerate(Lys_props):\n",
    "                region_mask = Lys_Ana == region.label\n",
    "                intersection = np.logical_and(region_mask, ERThresh_clean)\n",
    "                intersection_area = intersection.sum()\n",
    "                intersection_percent = (intersection_area / region.area * 100) if region.area > 0 else 0\n",
    "                \n",
    "                # Count connected components of the intersection\n",
    "                _, num_intersections = measure.label(intersection, return_num=True)\n",
    "                \n",
    "                ersheets_intersection_area = np.logical_and(region_mask, ERsheets).sum()\n",
    "                ersheets_percentage = (ersheets_intersection_area / region.area * 100) if region.area > 0 else 0\n",
    "\n",
    "                # Take the existing region dictionary and add new metrics\n",
    "                d = Lys_region_data[i].copy()\n",
    "                d.update({\n",
    "                    'Cell area': CellMask_bool.sum(),\n",
    "                    'ERsheets area': ERsheets_bool.sum(),\n",
    "                    'ERThresh_intersection_percentage': intersection_percent,\n",
    "                    'ERThresh_intersection_area': intersection_area,\n",
    "                    'ERThresh_num_intersection_areas': num_intersections,\n",
    "                    'ERsheets_intersection_percentage': ersheets_percentage\n",
    "                })\n",
    "\n",
    "                Lys_region_data_augmented.append(d)\n",
    "\n",
    "            # Convert to DataFrame\n",
    "            Lys_df = pd.DataFrame(Lys_region_data_augmented)\n",
    "            Lys_df.to_csv(os.path.join(folder_dir, f\"{base}_Cell_{CurrentCell+1}_Lysosomes.csv\"), index=False)\n",
    "\n",
    "            # --- Co-localisation metrics ---\n",
    "            NotSheets_Mask = CellMask - np.multiply(CellMask, ERsheets)\n",
    "\n",
    "            # Extract subregions for each\n",
    "            results = []\n",
    "\n",
    "            # IN SHEETS\n",
    "            img1_in = Lys * ERsheets\n",
    "            img2_in = ER * ERsheets\n",
    "            mask1_in = Lys_final * ERsheets\n",
    "            mask2_in = ERThresh_clean * ERsheets\n",
    "\n",
    "            result_in = compute_all_coefficients(img1_in, img2_in, mask1_in, mask2_in, region='In Sheets', ch1='Lys', ch2='ER')\n",
    "            results.append(result_in)\n",
    "\n",
    "            # NOT IN SHEETS\n",
    "            img1_out = Lys * NotSheets_Mask\n",
    "            img2_out = ER * NotSheets_Mask\n",
    "            mask1_out = Lys_final * NotSheets_Mask\n",
    "            mask2_out = ERThresh_clean * NotSheets_Mask\n",
    "\n",
    "            result_out = compute_all_coefficients(img1_out, img2_out, mask1_out, mask2_out, region='Not In Sheets', ch1='Lys', ch2='ER')\n",
    "            results.append(result_out)\n",
    "\n",
    "            # WHOLE CELL\n",
    "            Lys_Cell = Lys * CellMask\n",
    "            ER_Cell = ER * CellMask\n",
    "            \n",
    "            result_whole = compute_all_coefficients(\n",
    "                Lys_Cell, ER_Cell,\n",
    "                Lys_final, ERThresh_clean,\n",
    "                region='Whole Cell', \n",
    "                ch1='Lys', \n",
    "                ch2='ER'\n",
    "            )\n",
    "            results.append(result_whole)\n",
    "\n",
    "            df = pd.DataFrame(results)\n",
    "\n",
    "            # -----------------------------\n",
    "            # Save results\n",
    "            # -----------------------------\n",
    "            pd.DataFrame(results).to_csv( os.path.join(folder_dir, f\"{base}_Cell_{CurrentCell+1}_CoLocalisation.csv\"), index=False )\n",
    "\n",
    "            \n",
    "## Run the code\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    folder_dir =  os.path.join(os.path.dirname(__file__), \"../images\")\n",
    "    automated_analysis(folder_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
